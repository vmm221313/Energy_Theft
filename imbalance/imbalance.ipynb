{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('dba_utils/') # to access util files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as po\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "rm: cannot remove '__pycache__': No such file or directory\nCompiling dtw.pyx because it changed.\n[1/1] Cythonizing dtw.pyx\nrunning build_ext\nbuilding 'dtw' extension\ncreating build\ncreating build/temp.linux-x86_64-3.7\ngcc -pthread -B /home/varun/anaconda3/envs/tf2/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/varun/anaconda3/envs/tf2/lib/python3.7/site-packages/numpy/core/include -I/home/varun/anaconda3/envs/tf2/include/python3.7m -c dtw.c -o build/temp.linux-x86_64-3.7/dtw.o\nIn file included from \u001b[01m\u001b[K/home/varun/anaconda3/envs/tf2/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1832\u001b[m\u001b[K,\n                 from \u001b[01m\u001b[K/home/varun/anaconda3/envs/tf2/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n                 from \u001b[01m\u001b[K/home/varun/anaconda3/envs/tf2/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n                 from \u001b[01m\u001b[Kdtw.c:619\u001b[m\u001b[K:\n\u001b[01m\u001b[K/home/varun/anaconda3/envs/tf2/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\ngcc -pthread -shared -B /home/varun/anaconda3/envs/tf2/compiler_compat -L/home/varun/anaconda3/envs/tf2/lib -Wl,-rpath=/home/varun/anaconda3/envs/tf2/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/dtw.o -o /home/varun/Desktop/Projects/EnergyTheft/imbalance/utils/distances/dtw.cpython-37m-x86_64-linux-gnu.so\n"
    }
   ],
   "source": [
    "!bash ./utils/build-cython.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dba'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-46e5581cc7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maugment_train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Projects/EnergyTheft/imbalance/utils/augment.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDISTANCE_ALGORITHMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDISTANCE_ALGORITHMS_PARAMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_METHODS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_dist_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/EnergyTheft/imbalance/utils/constants.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utils/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_time_warping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dba'"
     ]
    }
   ],
   "source": [
    "from utils.augment import augment_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = po.read_csv('../data/processed/imputation/edtwbi.csv').sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['FLAG'] == 0]\n",
    "df_1 = df[df['FLAG'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "df_0 = df_0.sort_values('num_zeros')[:len(df_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersampled = po.concat([df_1, df_0], axis=0, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersampled['FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled = df_undersampled.drop(['num_zeros', 'FLAG'], axis=1)\n",
    "y_undersampled = df_undersampled['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled_train = X_undersampled[:int(0.6*len(X_undersampled))]\n",
    "y_undersampled_train = y_undersampled[:int(0.6*len(X_undersampled))]\n",
    "\n",
    "X_undersampled_val   = X_undersampled[int(0.6*len(X_undersampled)):int(0.8*len(X_undersampled))]\n",
    "y_undersampled_val   = y_undersampled[int(0.6*len(X_undersampled)):int(0.8*len(X_undersampled))]\n",
    "\n",
    "X_undersampled_test  = X_undersampled[int(0.8*len(X_undersampled)):]\n",
    "y_undersampled_test  = y_undersampled[int(0.8*len(X_undersampled)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled_train     = X_undersampled_train.to_numpy()[:, :, np.newaxis]\n",
    "X_undersampled_val       = X_undersampled_val.to_numpy()[:, :, np.newaxis]\n",
    "X_undersampled_test      = X_undersampled_test.to_numpy()[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_undersampled_train     = y_undersampled_train.to_numpy()\n",
    "y_undersampled_val       = y_undersampled_val.to_numpy()\n",
    "y_undersampled_test      = y_undersampled_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save undersampled data\n",
    "with open('../data/processed/training_data/undersampled.npz', 'wb') as f:\n",
    "    np.savez(f, X_train=X_undersampled_train, y_train=y_undersampled_train, X_val=X_undersampled_val, y_val=y_undersampled_val, X_test=X_undersampled_test, y_test=y_undersampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['num_zeros', 'FLAG'], axis=1)\n",
    "y = df['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:int(0.6*len(X))]\n",
    "y_train = y[:int(0.6*len(X))]\n",
    "\n",
    "X_val   = X[int(0.6*len(X)):int(0.8*len(X))]\n",
    "y_val   = y[int(0.6*len(X)):int(0.8*len(X))]\n",
    "\n",
    "X_test  = X[int(0.8*len(X)):]\n",
    "y_test  = y[int(0.8*len(X)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    12381\n1     2182\nName: FLAG, dtype: int64"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    4121\n1     733\nName: FLAG, dtype: int64"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    4155\n1     700\nName: FLAG, dtype: int64"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train     = X_train.to_numpy()[:, :, np.newaxis]\n",
    "X_val       = X_val.to_numpy()[:, :, np.newaxis]\n",
    "X_test      = X_test.to_numpy()[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train     = y_train.to_numpy()\n",
    "y_val       = y_val.to_numpy()\n",
    "y_test      = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data\n",
    "with open('../data/processed/training_data/standard.npz', 'wb') as f:\n",
    "    np.savez(f, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 2\n",
    "N       = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([12381,  2182])"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'augment_train_set' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a5a6a643942e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# augment the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_synth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_synth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_train_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_method_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'as'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dtw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'augment_train_set' is not defined"
     ]
    }
   ],
   "source": [
    "# augment the dataset\n",
    "X_train_synth, y_train_synth = augment_train_set(X_train, y_train, classes, N, limit_N = False, weights_method_name='as', distance_algorithm='dtw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "                syn_train_set, distance_algorithm = augment_function('as_dtw_dba_augment',\n",
    "                                                                     x_train, y_train, classes,\n",
    "                                                                     nb_prototypes, limit_N=False)\n",
    "                # get the synthetic train and labels\n",
    "                syn_x_train, syn_y_train = syn_train_set\n",
    "                # concat the synthetic with the reduced random train and labels\n",
    "                aug_x_train = np.array(x_train.tolist() + syn_x_train.tolist())\n",
    "                aug_y_train = np.array(y_train.tolist() + syn_y_train.tolist())\n",
    "\n",
    "                print(np.unique(y_train,return_counts=True))\n",
    "                print(np.unique(aug_y_train,return_counts=True))\n",
    "\n",
    "                y_pred = classifier.fit(aug_x_train, aug_y_train, x_test,\n",
    "                                        y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596883941037",
   "display_name": "Python 3.7.7 64-bit ('tf2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}